---
title: "Take_home_Ex1"
Author: "Mah Lian Khye"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# Overview

The recent shift in payment being made more digital, companies and organisations can more easily collect data and information that are linked to consumer habits. The transportation industry including public transport such as buses has also lean into this phenomenon. The information collected include travelling patterns that can help companies plan for more efficient routes or where heavy ridership is to be expected.

# Objectives

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

# Task

Here we will utilise bus travelling data at different time duration for plotting out geospatial data and analysing them using various statistical tools.

## Geovisualisation and Analysis

Computing passenger trips at the hexagonal level for the following time intervals:

-   Weekday morning peak, 6am to 9am
-   Weekday afternoon peak, 5pm to 8pm
-   Weekend/holiday morning peak, 11am to 2pm
-   Weekend/holiday evening peak, 4pm to 7pm

Display the geographical distribution using choropleth maps of the hexagons.

Combine all of the passenger trips made by all of the bus stops within a hexagon together

## Local Indicators of Spatial Association(LISA) Analysis

Utilise Queen's contiguity for performing LISA of the passenger trips by origin at hexagonal level Displat the LISA maps of the passenger trips at hexagonal level.

# Load Packages and Data

## Load packages

Here we will load the packages needed for this exercise and their respective functions - **sf**: - **tmap**: - **spdep**: - **tidyverse**: - **dplyr**: - **mapview**: - **sfdep**:

```{r}
pacman::p_load(sf,tmap,spdep,tidyverse, dplyr, mapview, sfdep, stplanr)
```

## Loading data

### Loading aspatial table

Here we will read all of the ridership from different bus stops in Oct 2023 and assign it to the variable.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

We will then extract the information from the following and assign them to different variables.

| Day               | Duration   | Variable name   |
|-------------------|------------|-----------------|
| Weekdays          | 6am - 9am  | weekdayAM_6_9   |
| Weekdays          | 5pm - 8pm  | weekdayPM_5_8   |
| Weekends/Holidays | 11am - 2pm | weekendAM_11_14 |
| Weekends/Holidays | 4pm - 7pm  | weekendPM_4_7   |

```{r}
weekdayAM_6_9 <- odbus %>% 
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

weekdayPM_5_8 <- odbus %>% 
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

weekendAM_11_14 <- odbus %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

weekendPM_16_19 <- odbus %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

### Loading Geospatial data

Next we will import all of the bus stops and their coordinates and attached it to the *busstop* variable.

```{r}
busstop <- st_read(dsn = "data/geospatial", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

We will first rename the bus stop column title for easier data joining.

```{r}
colnames(busstop)[colnames(busstop) == "BUS_STOP_N"] <- "ORIGIN_PT_CODE"
```

We will also import the layout of Singapore for excluding busstops that are not found in Singapore.
```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)

```

After that we will create the hexagons that will create the map layout. The hexagons will be shaped 250 x 250 cell size. All of the hexagons will also be given a grid id name that can be used for identifying each individual grid.

```{r}
center <- st_centroid(busstop)

area_honeycomb_grid <- st_make_grid(center, cellsize = c(250 * sqrt(3), 250 * 2), what = "polygons", square = FALSE)
honeycomb_grid_sf <- st_sf(area_honeycomb_grid) %>%
  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))

```

# Data processing

## Assigning individual bus stop to hexagons

First we will assign the bus stop point geometry data to each polygon using *st_intersection()*. The function assigns all of the points to a polygon by the point-set intersection of two geometries. Additional information [here](https://postgis.net/docs/ST_Intersection.html).

```{r}

valid_busstop <- st_intersection(busstop, mpsz)
busstop_hex <- st_intersection(valid_busstop, honeycomb_grid_sf) %>%
  st_drop_geometry()

```

## Duplication check

Here we will check for the presence of any duplication before we further process the data.

```{r}
duplicate1 <- weekdayAM_6_9 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()

duplicate2 <- weekdayPM_5_8 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()

duplicate3 <- weekendAM_11_14 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()

duplicate4 <- weekendPM_16_19 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

We can see which data points are duplicated here.

```{r}
c(duplicate1,duplicate2,duplicate3,duplicate4)
```

Finally we only keep data points that are unique using the *unique()* function.

```{r}
unique_weekdayAM <- unique(weekdayAM_6_9)
unique_weekdayPM <- unique(weekdayPM_5_8)
unique_weekendAM <- unique(weekendAM_11_14)
unique_weekendPM <- unique(weekendPM_16_19)
```

## Trip tabulation

Next we will then join the variables that we created earlier that contains the total number of trips at different time intervals and the *busstop_hex* variable together using **grid_id** column title that they have in common. The total number of trips made from each hexagon is then summed up together and placed under a new column named **TOT_TRIPS**.

```{r}
count_weekdayAM_6_9 <- left_join(unique_weekdayAM , busstop_hex) %>%
  group_by(grid_id) %>%
  summarise(TOT_TRIPS = sum(TRIPS))

count_weekdayPM_5_8 <- left_join(unique_weekdayPM , busstop_hex) %>%
  group_by(grid_id) %>%
  summarise(TOT_TRIPS = sum(TRIPS))

count_weekendAM_11_14 <- left_join(unique_weekendAM , busstop_hex) %>%
  group_by(grid_id) %>%
  summarise(TOT_TRIPS = sum(TRIPS))

count_weekendPM_16_19 <- left_join(unique_weekendPM , busstop_hex) %>%
  group_by(grid_id) %>%
  summarise(TOT_TRIPS = sum(TRIPS))


```


## Reassign polygon information

We will the reassign the polygon information from the hexagonal map that we have created earlier.

```{r}
poly_weekdayAM_6_9 <- left_join(honeycomb_grid_sf,count_weekdayAM_6_9)
poly_weekdayPM_5_8 <- left_join(honeycomb_grid_sf,count_weekdayPM_5_8)
poly_weekendAM_11_14 <- left_join(honeycomb_grid_sf,count_weekendAM_11_14)
poly_weekendPM_16_19 <- left_join(honeycomb_grid_sf,count_weekendPM_16_19)
```

## Filter for empty trips

Following that we will filter hexagons that have no trips to obtain only valid hexagons for mapping.

```{r}
grid_weekdayAM <- poly_weekdayAM_6_9 %>%
  filter(TOT_TRIPS > 0)

grid_weekdayPM <- poly_weekdayPM_5_8 %>%
  filter(TOT_TRIPS > 0)

grid_weekendAM <- poly_weekendAM_11_14 %>%
  filter(TOT_TRIPS > 0)

grid_weekendPM <- poly_weekendPM_16_19 %>%
  filter(TOT_TRIPS > 0)

```

# Choropleth map 

Here we will plot the choropleth map for the different time intervals. We will be using *tmap_mode("plot")* to create an interactive map. Although we will be coding in accessories such as the compass, they will not be displayed in the interactive map. However by writing them first, we can display them in subsequent maps once we view them in **plot** mode.

::: panel-tabset
## **Weekday 6am to 9am**

```{r}
tmap_mode("view")
mapA <- tm_shape(grid_weekdayAM)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Passenger trips generated Weekday 6am-9am",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 1) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from URA\n and Passenger trips data from LTA", 
             position = c("left", "bottom"))
mapA
```


The total number of ridership range from 1 to 357043 per hexagon. The range of the data are divided to quantile range bands for clearer distinction between ridership of each hexagon.

## **Weekday 5pm to 8pm**

```{r}
mapB <- tm_shape(grid_weekdayPM)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Reds",
          title = "Passenger trips") +
  tm_layout(main.title = "Passenger trips generated Weekday 5pm-8pm",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 1) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from URA\n and Passenger trips data from LTA", 
             position = c("left", "bottom"))
mapB
```

The total number of ridership range from 1 to 568845 per hexagon.

## **Weekend/Holidays 11am to 2pm**

```{r}
mapC <- tm_shape(grid_weekendAM)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Greens",
          title = "Passenger trips") +
  tm_layout(main.title = "Passenger trips generated Weekend/holidays 11am-2pm",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 1) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from URA\n and Passenger trips data from LTA", 
             position = c("left", "bottom"))
mapC

```

The total number of ridership range from 1 to 117609 per hexagon.

## **Weekend/Holidays 4pm to 7pm**

```{r}
mapD <- tm_shape(grid_weekendPM)+
  tm_fill("TOT_TRIPS", 
          style = "quantile", 
          palette = "Purples",
          title = "Passenger trips") +
  tm_layout(main.title = "Passenger trips generated Weekend/holidays 4pm-7pm",
            main.title.position = "center",
            main.title.size = 0.7,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 1) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from URA\n and Passenger trips data from LTA", 
             position = c("left", "bottom"))
mapD

```

The total number of ridership range from 1 to 114410 per hexagon.
:::

## Plot maps

We can also utilise a plot mode by using *tmap_mode("plot")*.

```{r}
tmap_mode("plot")
mapA
```


This allows for other accessories to be added such as compass and scales which might be useful depending on the application or use of the map.







## Choropleth map discussion

We can see that the total ridership over the weekends is lower than the weekday counterparts despite both being classified as peak hours. This difference is likely due to people travelling to or from work on the weekdays as compared to the weekends where there will be less traffic as people choose to stay at home or electing to travel to districts where it may be more accessible by other transportations such as trains.

# LISA

## Creating neighbour count column

Before we calculate LISA, we will add the number of neighbours to each dataset for the various grids. We will use *st_contiguity()* and add a neighbour column to the data points under a new variable name. By default, the Queen method of contiguity will be used for calculating the neighbours.


```{r}
wm_qA <- grid_weekdayAM %>%
    mutate(nb = st_contiguity(area_honeycomb_grid),
         .before = 1)

wm_qB <- grid_weekdayPM %>%
  mutate(nb = st_contiguity(area_honeycomb_grid),
         .before = 1)

wm_qC <- grid_weekendAM %>%
  mutate(nb = st_contiguity(area_honeycomb_grid),
         .before = 1)

wm_qD <- grid_weekendPM %>%
  mutate(nb = st_contiguity(area_honeycomb_grid),
         .before = 1)
```

Here we can use the *summary()* function to take a look at the different regions and the neighbours that they have.

::: panel-tabset
## **Weekday 6am to 9am**

```{r}
summary(wm_qA$nb)


```

We see that there are 1779 data points and they have an average of 4.3 neighbours. There are 12 hexagons with 0 neighbours and 450 hexagons with 6 neighbours.

## **Weekday 6am to 9am**

```{r}
summary(wm_qB$nb)
```

We see that there are 1780 data points and they have an average of 4.3 neighbours. There are 12 hexagons with 0 neighbours and 450 hexagons with 6 neighbours.

## **Weekday 6am to 9am**

```{r}
summary(wm_qC$nb)
```

We see that there are 1786 data points and they have an average of 4.3 neighbours. There are 11 hexagons with 0 neighbours and 454 hexagons with 6 neighbours.

## **Weekday 6am to 9am**

```{r}
summary(wm_qD$nb)
```

We see that there are 1775 data points and they have an average of 4.3 neighbours. There are 10 hexagons with 0 neighbours and 446 hexagons with 6 neighbours.
:::

## Neighbour count

Here we can convert the above neighbour count data into a variable dataframe for more direct comparison

```{r}
df_countsA <- wm_qA %>%
  summarise(vector_length = map_dbl(nb, ~length(.))) %>%
  group_by(vector_length) %>%
  summarise(count = n()) %>%
  st_drop_geometry()

df_countsB <- wm_qB %>%
  summarise(vector_length = map_dbl(nb, ~length(.))) %>%
  group_by(vector_length) %>%
  summarise(count = n())%>%
  st_drop_geometry()

df_countsC <- wm_qC %>%
  summarise(vector_length = map_dbl(nb, ~length(.))) %>%
  group_by(vector_length) %>%
  summarise(count = n())%>%
  st_drop_geometry()

df_countsD <- wm_qD %>%
  summarise(vector_length = map_dbl(nb, ~length(.))) %>%
  group_by(vector_length) %>%
  summarise(count = n())%>%
  st_drop_geometry()

result <- bind_rows(
  mutate(df_countsA, dataset = "Weekday 6am to 9am"),
  mutate(df_countsB, dataset = "Weekday 5pm to 8pm"),
  mutate(df_countsC, dataset = "Weekends/holidays 11am to 2pm"),
  mutate(df_countsD, dataset = "Weekends/holidays 4pm to 7pm")
) %>%
  rename("number of neighbours" = vector_length, count = count)


```
## Compiling neighbour count

We will use the *bind_rows()* function to group all of the neighbour count data together and rearrange them.

```{r}

result <- bind_rows(
  mutate(df_countsA, dataset = "Weekday 6am to 9am"),
  mutate(df_countsB, dataset = "Weekday 5pm to 8pm"),
  mutate(df_countsC, dataset = "Weekends/holidays 11am to 2pm"),
  mutate(df_countsD, dataset = "Weekends/holidays 4pm to 7pm")
) %>%
  rename("number_of_neighbours" = vector_length, count = count)




result <- result %>%
  group_by(dataset) %>%
  arrange(desc(number_of_neighbours)) %>%
  mutate(number_of_neighbours = factor(number_of_neighbours, levels = unique(number_of_neighbours)))
```



## Plotting neighbour count bar chart

Next we will use ggplot to plot the bar chart for the number of hexagons with differing neighbour count and the different time interval. 
```{r}


ggplot(result, aes(x = number_of_neighbours, y = count, fill = dataset)) +
  stat_summary(fun = "sum", geom = "bar", position = "dodge") +
  scale_fill_manual(values = c(
                   "Weekday 6am to 9am" = "blue4",
                   "Weekday 5pm to 8pm" = "brown2",
                   "Weekends/holidays 11am to 2pm" = "palegreen",
                   "Weekends/holidays 4pm to 7pm" = "mediumpurple1")) 
  labs(title = "Number of Neighbours Counts",
       x = "Number of Neighbours",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



Overall we see a decrease in ridership between weekdays and weekends however the number of bus stops that are utilised remains fairly the same. This may mean an overall decrease in ridership for all bus stops but the bus stops that are utilised for boarding remain the same.

Next we will have to remove all of the data points with 0 neighbours using *filter* and **purrr** package.

```{r}
wm_qA_process <- wm_qA %>%
   filter(!purrr::map_lgl(nb, ~ all(. == 0)))
wm_qB_process <- wm_qB %>%
   filter(!purrr::map_lgl(nb, ~ all(. == 0)))
wm_qC_process <- wm_qC %>%
   filter(!purrr::map_lgl(nb, ~ all(. == 0)))
wm_qD_process <- wm_qD %>%
   filter(!purrr::map_lgl(nb, ~ all(. == 0)))
```

## Spatial weights

```{r}
wm_qA_weighted <- wm_qA_process %>% 
  mutate(nb = st_contiguity(area_honeycomb_grid),
         wt = st_weights(nb, style = "W"),
         .before = 1)
wm_qB_weighted <- wm_qB_process %>% 
  mutate(nb = st_contiguity(area_honeycomb_grid),
         wt = st_weights(nb, style = "W"),
         .before = 1)
wm_qC_weighted <- wm_qC_process %>% 
  mutate(nb = st_contiguity(area_honeycomb_grid),
         wt = st_weights(nb, style = "W"),
         .before = 1)
wm_qD_weighted <- wm_qD_process %>% 
  mutate(nb = st_contiguity(area_honeycomb_grid),
         wt = st_weights(nb, style = "W"),
         .before = 1)
```

## Local Moran's I

Here we will be using the *local_moran()* function to calculate the local Moran's I for each region or county.

```{r}
lisaA <- wm_qA_weighted %>% 
  mutate(local_moran = local_moran(
    TOT_TRIPS, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
lisaB <- wm_qB_weighted %>% 
  mutate(local_moran = local_moran(
    TOT_TRIPS, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
lisaC <- wm_qC_weighted %>% 
  mutate(local_moran = local_moran(
    TOT_TRIPS, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
lisaD <- wm_qD_weighted %>% 
  mutate(local_moran = local_moran(
    TOT_TRIPS, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_moran)
```

The output will be a data fram containing the ii, eii, var_ii, z_ii, p_ii, p_ii_sim and p_folded_sum.

## Combined visualisation of local Moran's I and p-value

Here we will place the maps next to each other.

::: panel-tabset
## **Weekday 6am to 9am**

```{r}
tmap_mode("plot")
map1A <- tm_shape(lisaA) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of the total number of trips",
            main.title.size = 0.8)

map2A <- tm_shape(lisaA) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1A, map2A, ncol = 2)
```

## **Weekday 5pm to 8pm**

```{r}
tmap_mode("plot")
map1B <- tm_shape(lisaB) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of the total number of trips",
            main.title.size = 0.8)

map2B <- tm_shape(lisaB) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1B, map2B, ncol = 2)
```

## **Weekend/Holidays 11am to 2pm**

```{r}
tmap_mode("plot")
map1C <- tm_shape(lisaC) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of the total number of trips",
            main.title.size = 0.8)

map2C <- tm_shape(lisaC) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1C, map2C, ncol = 2)
```

## **Weekend/Holidays 4pm to 7pm**

```{r}
tmap_mode("plot")
map1D <- tm_shape(lisaD) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of the total number of trips",
            main.title.size = 0.8)

map2D <- tm_shape(lisaD) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1D, map2D, ncol = 2)
```
:::

## Visualisation of LISA

Here will will visualise LISA where we can see the presence of outliers and clusters. More information can be found [here](https://isss624-liankhye.netlify.app/hands-on_ex02/hands-on_ex2_3#lisa-cluster-map). The following is a newer method for calculating LISA, and require shorter and more concise steps such as not having to manually form the high-high, high-low, low-high and low-low quadrants. Just make sure that if the data is skewed, we will have to use the median for forming the quadrant.

::: panel-tabset
## **Weekday 6am to 9am**

```{r}
lisa_sigA <- lisaA  %>%
  filter(p_ii < 0.05)
tmap_mode("view")
tm_shape(lisaA) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sigA) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

## **Weekday 5pm to 9pm**

```{r}
lisa_sigB <- lisaB  %>%
  filter(p_ii < 0.05)
tmap_mode("view")
tm_shape(lisaB) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sigB) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

## **Weekends/Holidays 11am to 2pm**

```{r}
lisa_sigC <- lisaC  %>%
  filter(p_ii < 0.05)
tmap_mode("view")
tm_shape(lisaC) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sigC) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

## **Weekends/Holidays 11am to 2pm**

```{r}
lisa_sigD <- lisaD  %>%
  filter(p_ii < 0.05)
tmap_mode("view")
tm_shape(lisaD) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sigD) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```
:::

# Additional processing

## Passenger flow visualisation

### Origin and destination grouping

We can also take a look at passenger glow between the different hexes by plotting the desire lines. We will first need to obtain the total number of trips of each intervals that are grouped by their origin followed by their destination.
```{r}
des_weekdayAM_6_9 <- odbus %>% 
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

des_weekdayPM_5_8 <- odbus %>% 
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

des_weekendAM_11_14 <- odbus %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

des_weekendPM_16_19 <- odbus %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

```

### Joining destination table and grid

Since we have drop 

Using the grid that we have created in the beginning, we will now join the data that contains the destination together with the grid.

```{r}
combn_des_weekdayAM_6_9 <- left_join(des_weekdayAM_6_9,busstop_hex) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_GRID = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)

combn_des_weekdayPM_5_8 <- left_join(des_weekdayPM_5_8,busstop_hex) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_GRID = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)

combn_des_weekendAM_11_14 <- left_join(des_weekendAM_11_14,busstop_hex) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_GRID = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)

combn_des_weekendPM_16_19 <- left_join(des_weekendPM_16_19,busstop_hex) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_GRID = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)


```

### Removing duplicates

We will then remove any duplicates using the *unique()* function.

```{r}
uni_des_weekdayAM_6_9 <- unique(combn_des_weekdayAM_6_9)
uni_des_weekdayPM_5_8 <- unique(combn_des_weekdayPM_5_8)
uni_des_weekendAM_11_14 <- unique(combn_des_weekendAM_11_14)
uni_des_weekendPM_16_19 <- unique(combn_des_weekendPM_16_19)
```

### Rejoin hexagonal information

We can then rejoin the hexagonal information back using *left_join()* function.

```{r}
poly_des_weekdayAM_6_9 <- left_join(uni_des_weekdayAM_6_9 , busstop_hex,
            by = c("DESTIN_BS" = "ORIGIN_PT_CODE"))
poly_des_weekdayPM_5_8 <- left_join(uni_des_weekdayPM_5_8 , busstop_hex,
            by = c("DESTIN_BS" = "ORIGIN_PT_CODE"))
poly_des_weekendAM_11_14 <- left_join(uni_des_weekendAM_11_14 , busstop_hex,
            by = c("DESTIN_BS" = "ORIGIN_PT_CODE"))
poly_des_weekendPM_16_19 <- left_join(uni_des_weekendPM_16_19 , busstop_hex,
            by = c("DESTIN_BS" = "ORIGIN_PT_CODE"))

```
### Recheck unique data

We will then recheck for unique data points by running *unique()* again.

```{r}
uniP_des_weekdayAM_6_9 <- unique(poly_des_weekdayAM_6_9)
uniP_des_weekdayPM_5_8 <- unique(poly_des_weekdayPM_5_8)
uniP_des_weekendAM_11_14 <- unique(poly_des_weekendAM_11_14)
uniP_des_weekendPM_16_19 <- unique(poly_des_weekendPM_16_19)

```

### Sum total trips

We will then sum up the total number of trips made from a bus stop of origin to the destination using *group_by()* for sorting. Putting multiple arguments into the function allows for the sub categorising the data. This way we can track the drop off point of the passengers.

```{r}
ori_des_weekdayAM_6_9 <- uniP_des_weekdayAM_6_9 %>%
  rename(DESTIN_GRID = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_GRID, DESTIN_GRID) %>%
  summarise(PEAK = sum(TRIPS))

ori_des_weekdayPM_5_8 <- uniP_des_weekdayPM_5_8 %>%
  rename(DESTIN_GRID = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_GRID, DESTIN_GRID) %>%
  summarise(PEAK = sum(TRIPS))

ori_des_weekendAM_11_14 <- uniP_des_weekendAM_11_14 %>%
  rename(DESTIN_GRID = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_GRID, DESTIN_GRID) %>%
  summarise(PEAK = sum(TRIPS))

ori_des_weekendPM_16_19 <- uniP_des_weekendPM_16_19 %>%
  rename(DESTIN_GRID = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_GRID, DESTIN_GRID) %>%
  summarise(PEAK = sum(TRIPS))
```

## Visualisation

We will first remove any intra-hexagonal travel.
```{r}
R_weekdayAM_6_9 <- ori_des_weekdayAM_6_9[ori_des_weekdayAM_6_9$ORIGIN_GRID!=ori_des_weekdayAM_6_9$DESTIN_GRID,]
R_weekdayPM_5_8 <- ori_des_weekdayPM_5_8[ori_des_weekdayPM_5_8$ORIGIN_GRID!=ori_des_weekdayPM_5_8$DESTIN_GRID,]
R_weekendAM_11_14 <- ori_des_weekendAM_11_14[ori_des_weekendAM_11_14$ORIGIN_GRID!=ori_des_weekendAM_11_14$DESTIN_GRID,]
R_weekendPM_16_19 <- ori_des_weekendPM_16_19[ori_des_weekendPM_16_19$ORIGIN_GRID!=ori_des_weekendPM_16_19$DESTIN_GRID,]
```

## Create desire lines

Next we will visualise all of the flow or connections between different bus stops from a subzone to another using the *od2line()* function from the **stplanr** package.

```{r}
flow_weekdayAM_6_9 <- od2line(flow = R_weekdayAM_6_9, 
                    zones = honeycomb_grid_sf,
                    zone_code = "grid_id")

flow_weekdayPM_5_8 <- od2line(flow = R_weekdayPM_5_8, 
                    zones = honeycomb_grid_sf,
                    zone_code = "grid_id")

flow_weekendAM_11_14 <- od2line(flow = R_weekendAM_11_14, 
                    zones = honeycomb_grid_sf,
                    zone_code = "grid_id")

flow_weekendPM_16_19 <- od2line(flow = R_weekendPM_16_19, 
                    zones = honeycomb_grid_sf,
                    zone_code = "grid_id")

```


## Visualise desire lines

We can then visualise this flow using the following code. Since the passenger flow is high, it is better to limit the visualisation. Here we will use a flow passenger flow from hexagons to hexagons of 1500 or more.

::: panel-tabset
## **Weekday 6am to 9am**

```{r}
tm_shape(grid_weekdayAM) +
  tm_polygons() +
flow_weekdayAM_6_9 %>%  
  filter(PEAK >= 1500) %>%
tm_shape() +
  tm_lines(lwd = "PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)


```

## **Weekday 5pm to 8pm**

```{r}
tm_shape(grid_weekdayPM) +
  tm_polygons() +
flow_weekdayPM_5_8 %>%  
  filter(PEAK >= 1500) %>%
tm_shape() +
  tm_lines(lwd = "PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)

```

## **Weekend 11am to 2pm**

```{r}
tm_shape(grid_weekendAM) +
  tm_polygons() +
flow_weekendAM_11_14 %>%  
  filter(PEAK >= 1500) %>%
tm_shape() +
  tm_lines(lwd = "PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

## **Weekend 4pm to 7pm**

```{r}
tm_shape(grid_weekendPM) +
  tm_polygons() +
flow_weekendPM_16_19 %>%  
  filter(PEAK >= 1500) %>%
tm_shape() +
  tm_lines(lwd = "PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)

```


:::

