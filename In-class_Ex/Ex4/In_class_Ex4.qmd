---
title: "In-class_Ex04"
---

# Overview

In this in-class exercise, we will perform the following tasks:

-   perform geocoding using data from data.gov.sg
-   calibrate geographically weighted poisson regression

# Loading packages and data

## Loading packages

```{r}
pacman::p_load(tidyverse,sf,httr,tmap, performance)
```

## Geocosing using SLA API
Address geocoding is the process of taking an aspatial decription of a location such as an address and returning a coordinate.

SLA hosts a geocoding service called OneMap API. It uses an address data and returns X-Y coordinates and latitude-longitude coordinates information.



```{r}

url <- "https://www.onemap.gov.sg/api/common/elastic/search"
csv <- read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes <- csv$`postal_code`

found <- data.frame()
not_found <-data.frame()
for (postcode in postcodes){
query<-list('searchVal'=postcode,'returnGeom' = 'Y', 'getAddrDetails' = 'Y', 'pageNum' = '1')
res<- GET(url,query=query)
if((content(res)$found)!=0){
found<-rbind(found,data.frame(content(res))[4:13])

} else{
  not_found =data.frame(postcode)}

}
```
Next we will search for any postal codes without a school.
```{r}
#| eval: false
merged = merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)
write.csv(merged, file = "data/aspatial/schools.csv")
write.csv(not_found, file = "data/aspatial/not_found.csv")



```

Here we find out that **Zhenghua Secondary** has missing longitude and latitude information, We will insert it manually into the **schools.csv**.

# Converting an aspatial data into a simple feature tibble data.frame

## importing and tidying *schools* data
```{r}
schools <- read_csv("data/aspatial/schools.csv") %>%
  rename(latitude=results.LATITUDE , longtitude = results.LONGITUDE ) %>%
  select(2:3,40:41)

```
## converting an aspatial data into sf tibble data.frame
Next we will convert the aspatial data into a simple feature tibble data.frame called *schools_sf* using *st_as_sf()*. The following code converts 2 points into a single point and convert from decimal degree to projected coordinate system which is in meters.

It is important to standardise the type of geocoordinate system used.

```{r}
schools_sf<-st_as_sf(schools,
                     coords = c("longtitude", "latitude"),
                     crs = 4326) %>%
  st_transform(crs = 3414)
```

## Plotting a point simple feature later
To ensure that *schools* sf tibble data.frame has been projected and converted correctly, we can plot the schools point data for visual inspection.

```{r}

tmap_mode("view")
tm_shape(schools_sf)+
tm_dots()+
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

# Preparing geospatial data

We will first import the planning subzones of Singapore.

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MP14_SUBZONE_WEB_PL") %>%
  st_transform(crs = 3414)
```
Next we will count the number of schools that can be found within each subzone.
```{r}
mpsz$`SCHOOL_COUNT` <- lengths(
  st_intersects(
    mpsz, schools_sf
  )
)
```

```{R}
summary(mpsz$SCHOOL_COUNT)
```
## Import business data

Here we will import the business geospatial data as our factor when considering the attractiveness factor.
```{r}
biz <- st_read(dsn = "data/geospatial",
                   layer = "Business")
```

We can then map out the locations of various businesses in Singapore. We will include the *tmap_options(check.and.fix = TRUE)* to the code to help close any unclosed polygons.

```{r}
tmap_options(check.and.fix = TRUE)  #polygon may not close, so need to auto close
tm_shape(mpsz)+  #sg boundary
  tm_polygons()+  #sg boundary
  tm_shape(biz)+  #biz layer
  tm_dots()
```

We can then take a look at the summary of the various businesses being spread out across Singapore.
```{r}
mpsz$BIZ_COUNT <- lengths(st_intersects(mpsz, biz))
summary(biz)
```

# Data intergration and wrangling

Here we will read the flow data from the rds file that we have created from the hands on ex.

```{r}
flow_data <- read_rds("data/rds/flow_data_tidy.rds")
glimpse(flow_data)
```

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,
  0, flow_data$MORNING_PEAK)
flow_data$offset<-ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,
  0.000001,1)

inter_zonal_flow<-flow_data%>%
  filter(FlowNoIntra >0)
inter_zonal_flow <-inter_zonal_flow %>%
  rename(TRIPS = MORNING_PEAK,
         DIST = dist)
```



## Origing(Production) constrained SIM

Firstly we will increae the amount of printed rows for R.
```{r}
getOption("max.print")
options(max.print=1000000)
```
Here we will fit an origin constrained SIM by using the code chunk below.

```{r}
orcSIM_Poisson <- glm(formula = TRIPS ~
                        ORIGIN_SZ + 
                        log(SCHOOL_COUNT) +  #use attractiveness factors
                        log(RETAIL_COUNT)+
                        log(DIST)+
                        log(DIST) - 1,  #have - 1 to remove intersept, already constrain to origin
                      family = poisson(link = "log"),
                      data = inter_zonal_flow,
                      na.action = na.exclude)
summary(orcSIM_Poisson)

```
What we want is the Estimate log(SCHOOL_COUNT) and log(RETAIL_COUNT) which are attractiveness factors and will tend to be positive. 
log(DIST) must be negative.

p-value for all logs have to be less than 0.05 to be significant for attractiveness.

## Goodness-of-fit

Here we will create our own function for calculating R2

```{r}
CalcRSquared <- function(observed, estimated){
  r<-cor(observed, estimated)
  R2<-r^2
  R2
  }

```

Next we will apply the R2 function to our data.
```{r}
CalcRSquared(orcSIM_Poisson$data$TRIPS, orcSIM_Poisson$fitted.values)

```
The R2 measures how well it explains factor affects flow
```{r}
performance_rmse(orcSIM_Poisson, normalized = FALSE)  #normalized will set mean to 0 like a z distrib
```
Root mean square error(RMSE) measures how well the factors estimates flow, bigger = less nice fitting.
An average 2613 trips false estimates

# Doubly constrained

```{r}
dbcSIM_Poisson <- glm(formula = TRIPS~
                        ORIGIN_SZ + 
                        DESTIN_SZ + 
                        log(DIST), # no -1 cus no attractiveness btw origin and des
                      family = poisson(link = "log"),
                      data = inter_zonal_flow,
                      na.action = na.exclude)

```

## Goodness-of-fit

Here we can apply the R2 function again.

```{r}
CalcRSquared(dbcSIM_Poisson$data$TRIPS, dbcSIM_Poisson$fitted.values)
```

# Model Comparison

We will first convert the models that we have created into a list.

```{r}
model_list <- list(originConstrained=orcSIM_Poisson,
                   doublyConstrained=dbcSIM_Poisson)

```
We can then finally use the *compare_performance()* function of the **performance** package to check for the better model.


```{r}
compare_performance(model_list, metrics = "RMSE")

```

A smaller RMSE represents a better model
